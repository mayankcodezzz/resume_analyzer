1. **STEP 1: Project Setup and Initial Git Repository**
GOAL : Set up the project structure and initialize a Git repository.

Project Setup and Initial Git Repository
1. Create the Project Directory and Clone the Empty Repo
 - git clone "URL"
2. Get in the project Directory 
 - cd resume_analyzer
3. Open Project in Vs code 
 - code . 

Create the Directory Structure
- This structure separates our app logic (main), reusable libraries (lib), utilities (utils), and data files (data).
- Use the terminal or your editor to create the folder structure:
resume_analyzer/
├── main/
│   └── app.py
├── lib/
│   ├── groq_handler.py
│   ├── resume_analyzer.py
│   └── text_processor.py
├── utils/
│   ├── config.py
│   ├── logger.py
│   ├── file_utils.py
│   └── prompt_loader.py
├── data/
│   ├── logs/
│   └── prompts.json
├── .env
├── requirements.txt
└── README.md 

Add a README
    # Resume Analyzer
    A Streamlit app to analyze resumes using the Groq API.

Initialize Git
    git add README.md
    git status
    git commit -m "Initial commit: Project setup with README"
    git push origin main


2. **STEP 2: Set Up Dependencies**
GOAL : Install required packages and configure the environment.

Edit requirements.txt
streamlit
groq
pymupdf
python-docx
python-dotenv

Install Dependencies
- pip install -r requirements.txt

Set Up .env for the Groq API Key Go to https://console.groq.com/keys, sign up/login, 
and generate an API key. Paste it here. The .env file keeps secrets safe.
- GROQ_API_KEY=your_key_here
- Add .env to .gitignore

Commit
We’ve installed dependencies to build our app and secured our API key. Never commit .env to GitHub!
- git add requirements.txt .gitignore
- git commit -m "Add dependencies and environment setup"
- git push origin main


3. **STEP 3: Basic Streamlit App for File Upload**
GOAL : Create a simple Streamlit app to upload a resume and display its text.

*Edit main/app.py*
import streamlit as st
def main():
    st.title("Resume Analyzer")
    st.subheader("Upload a PDF or Word Resume")
    uploaded_file = st.file_uploader("Upload Resume", type=["pdf", "docx"])
    if uploaded_file:
        st.write("File uploaded:", uploaded_file.name)
        # Placeholder for text extraction
        st.write("Text extraction coming soon!")

if __name__ == "__main__":
    main()

*Run the App*
    In the terminal: streamlit run main/app.py
    Show the UI: "You’ll see a title, subtitle, and file uploader. Upload a PDF or DOCX to see the filename."

*Commit*
- git add main/app.py
- git commit -m "Add basic Streamlit app for file upload"
- git push origin main


4. **STEP 4: Extract Text from Uploaded Files**
GOAL : Add text extraction for PDF and DOCX files.

*Edit lib/text_processor.py*
import fitz  # type: ignore # PyMuPDF - Library for handling PDF files
from docx import Document  # Library for handling Word (.docx) files

class TextProcessor:
    """A class to process and extract text from PDF and DOCX files."""
    
    def __init__(self):
        """Initialize the TextProcessor class.
        Currently no initialization parameters are needed."""
        pass

    def extract_text_from_pdf(self, pdf_path):
        """Extract text content from a PDF file.
        
        Args:
            pdf_path (str): Path to the PDF file to be processed
            
        Returns:
            str: Extracted text from all pages joined by newlines
        """
        # Open the PDF file using PyMuPDF
        doc = fitz.open(pdf_path)
        # Extract text from each page and join with newline characters
        text = "\n".join([page.get_text("text") for page in doc])
        # Close the document to free up resources
        doc.close()
        return text

    def extract_text_from_docx(self, docx_path):
        """Extract text content from a DOCX file.
        
        Args:
            docx_path (str): Path to the DOCX file to be processed
            
        Returns:
            str: Extracted text from all paragraphs joined by newlines
        """
        # Open the DOCX file using python-docx
        doc = Document(docx_path)
        # Extract text from each paragraph and join with newline characters
        text = "\n".join([para.text for para in doc.paragraphs])
        return text

    def extract_text(self, file_path, file_extension):
        """Extract text from a file based on its extension.
        
        Args:
            file_path (str): Path to the file to be processed
            file_extension (str): File extension (without dot) to determine processing method
            
        Returns:
            str: Extracted text from the file, empty string if extension not supported
        """
        # Handle PDF files
        if file_extension == "pdf":
            return self.extract_text_from_pdf(file_path)
        # Handle DOCX files
        elif file_extension == "docx":
            return self.extract_text_from_docx(file_path)
        # Return empty string for unsupported file types
        return ""

*Update main/app.py*
import os  # Operating system interfaces for file handling
import sys
# Add the project root directory to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import streamlit as st  # Web app framework for creating interactive interfaces
from lib.text_processor import TextProcessor  # Custom class for text extraction

def main():
    """Main function to run the Streamlit Resume Analyzer application."""
    # Set the title of the web application
    st.title("Resume Analyzer")
    # Add a subheader to provide context
    st.subheader("Upload a PDF or Word Resume")
    
    # Create a file uploader widget accepting PDF and DOCX files
    uploaded_file = st.file_uploader("Upload Resume", type=["pdf", "docx"])
    
    # Check if a file is uploaded and extract button is clicked
    if uploaded_file and st.button("Extract Text"):
        # Get the file extension from the uploaded file name
        file_extension = uploaded_file.name.split(".")[-1].lower()
        # Define a temporary file path for processing
        temp_path = f"temp_resume.{file_extension}"
        
        # Save the uploaded file temporarily to disk
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Create an instance of TextProcessor to handle text extraction
        processor = TextProcessor()
        # Extract text using the appropriate method based on file extension
        extracted_text = processor.extract_text(temp_path, file_extension)
        
        # Clean up by removing the temporary file
        os.remove(temp_path)
        
        # Display the extracted text section
        st.write("Extracted Text:")
        # Show the extracted text in a scrollable text area
        st.text_area("Text", extracted_text, height=300)
# Entry point of the script - runs the application when executed directly.
if __name__ == "__main__":
    main()

*Test*
    - Run streamlit run main/app.py, upload a file, and click "Extract Text" to see the output.

*Commit*
- git add lib/text_processor.py main/app.py
- git commit -m "Add text extraction for PDF and DOCX files"
- git push origin main